<!DOCTYPE HTML><html lang=zh-CN><head><meta charset=utf-8><meta name=keywords content="生成式人工智能导论-Chap.3, MUG-chen&#39;s Blog"><meta name=description content=生成式人工智能导论第三部分><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=no"><meta name=renderer content=webkit|ie-stand|ie-comp><meta name=mobile-web-app-capable content=yes><meta name=format-detection content="telephone=no"><meta name=apple-mobile-web-app-capable content=yes><meta name=apple-mobile-web-app-status-bar-style content=black-translucent><meta name=referrer content=no-referrer-when-downgrade><title>生成式人工智能导论-Chap.3 | MUG-chen&#39;s Blog</title><link rel=icon type=image/png href=/favicon.png><style>body{background-image:url(https://mug-chensblog-1310677143.cos.ap-beijing.myqcloud.com/Vivid%20theory.webp);background-repeat:no-repeat;background-size:100% 100%;background-attachment:fixed}</style><link rel=stylesheet type=text/css href=/libs/awesome/css/all.min.css><link rel=stylesheet type=text/css href=/libs/materialize/materialize.min.css><link rel=stylesheet type=text/css href=/libs/aos/aos.css><link rel=stylesheet type=text/css href=/libs/animate/animate.min.css><link rel=stylesheet type=text/css href=/libs/lightGallery/css/lightgallery.min.css><link rel=stylesheet type=text/css href=/css/matery.css><link rel=stylesheet type=text/css href=/css/my.css><link rel=stylesheet type=text/css href=/css/dark.css media=none onload='"all"!=media&&(media="all")'><link rel=stylesheet href=/libs/tocbot/tocbot.css><link rel=stylesheet href=/css/post.css><script src=/libs/jquery/jquery-3.6.0.min.js></script><link rel=stylesheet type=text/css href=/css/loading.css><meta name=generator content="Hexo 7.1.1"></head><body><header class=navbar-fixed><nav id=headNav class="bg-color nav-transparent"><div id=navContainer class="nav-wrapper container"><div class=brand-logo><a href=/ class="waves-effect waves-light"><img src=/medias/logo.png class=logo-img alt=LOGO> <span class=logo-span>MUG-chen&#39;s Blog</span></a></div><a href=# data-target=mobile-nav class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href=/ class="waves-effect waves-light"><i class="fas fa-home" style=zoom:.6></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href=/tags class="waves-effect waves-light"><i class="fas fa-tags" style=zoom:.6></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href=/categories class="waves-effect waves-light"><i class="fas fa-bookmark" style=zoom:.6></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href=/archives class="waves-effect waves-light"><i class="fas fa-archive" style=zoom:.6></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href=/about class="waves-effect waves-light"><i class="fas fa-user-circle" style=zoom:.6></i> <span>关于</span></a></li><li><a href=#searchModal class="modal-trigger waves-effect waves-light"><i id=searchIcon class="fas fa-search" title=搜索 style=zoom:.85></i></a></li><li><a href=javascript:; class="waves-effect waves-light" onclick=switchNightMode() title=深色/浅色模式><i id=sum-moon-icon class="fas fa-sun" style=zoom:.85></i></a></li></ul><div id=mobile-nav class="side-nav sidenav"><div class="mobile-head bg-color"><img src=/medias/logo.png class="logo-img circle responsive-img"><div class=logo-name>MUG-chen&#39;s Blog</div><div class=logo-desc>Never really desperate, only the lost of the soul.</div></div><ul class="menu-list mobile-menu-list"><li class=m-nav-item><a href=/ class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class=m-nav-item><a href=/tags class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class=m-nav-item><a href=/categories class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class=m-nav-item><a href=/archives class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class=m-nav-item><a href=/about class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li><div class=divider></div></li><li><a href=https://github.com/MUG-chen/MUG-chen.github.io class="waves-effect waves-light" target=_blank><i class="fab fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href=https://github.com/MUG-chen/MUG-chen.github.io class="github-corner tooltipped hide-on-med-and-down" target=_blank data-tooltip="Fork Me" data-position=left data-delay=50><svg viewBox="0 0 250 250" aria-hidden=true><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill=currentColor style="transform-origin:130px 106px" class=octo-arm></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill=currentColor class=octo-body></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style=background-image:url(/medias/featureimages/12.jpg)><div class=container style=right:0;left:0><div class=row><div class="col s12 m12 l12"><div class=brand><h1 class="description center-align post-title">生成式人工智能导论-Chap.3</h1></div></div></div></div></div><main class="post-container content"><div class=row><div id=main-content class="col s12 m12 l9"><div id=artDetail><div class=card><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class=article-tag><a href=/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/ ><span class="chip bg-color">人工智能</span> </a><a href=/tags/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/ ><span class="chip bg-color">生成式人工智能导论</span> </a><a href=/tags/Introduction-to-Generative-Artificial-Intelligence/ ><span class="chip bg-color">Introduction to Generative Artificial Intelligence</span></a></div></div><div class="col s5 right-align"><div class=post-cate><i class="fas fa-bookmark fa-fw icon-category"></i> <a href=/categories/Study-Notes/ class=post-category>Study Notes </a><a href=/categories/Study-Notes/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/ class=post-category>人工智能</a></div></div></div><div class=post-info><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2025-12-09</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2026-01-05</div><div class=info-break-policy><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3k</div></div></div><hr class=clearfix><link rel=stylesheet href=/libs/prism/prism.min.css><div class="card-content article-card-content"><div id=articleContent><blockquote><p>本系列生成式人工智能导论博文基于国立台湾大学李宏毅老师发布的课程视频整理而来, 仅用作复习参考.<br>可以算是人工智能领域的入门课程.<br>需要明确的是, 李宏毅老师上传的课程已经是2024年的课程, 距今有两年的时间, 知识难免有过时的可能, 如果出现了这种情况, 博主会尽可能补足当前的状态.</p></blockquote><h1 id=生成式人工智能导论-Chap-3-语言模型的训练过程><a href=#生成式人工智能导论-Chap-3-语言模型的训练过程 class=headerlink title="生成式人工智能导论 Chap.3 语言模型的训练过程"></a>生成式人工智能导论 Chap.3 语言模型的训练过程</h1><p>在正式了解模型的训练过程前, 我们得回顾一下几个知识点:</p><ol><li>语言模型一直在做文字接龙的工作</li><li>语言模型本质上是个包含数十亿参数的函数, 通过训练资料将函数的参数确定下来的过程, 就是模型训练(Training &#x2F; Learning)</li><li>参数确定下来后, 进行文字接龙的测试工作, 叫做测试 &#x2F; 推论(Testing &#x2F; Inference)</li></ol><h2 id=3-1-寻找参数的挑战><a href=#3-1-寻找参数的挑战 class=headerlink title="3.1 寻找参数的挑战"></a>3.1 寻找参数的挑战</h2><h3 id=3-1-1-最佳化与超参数><a href=#3-1-1-最佳化与超参数 class=headerlink title="3.1.1 最佳化与超参数"></a>3.1.1 最佳化与超参数</h3><p>我们说机器学习一直在尝试找到确定的参数, 但是很显然, 参数的取值可能性太多了. 如何取到一组参数值, 使得这个模型运行起来效果最佳, 是一个很难解决的问题.<br>这个玩意在机器学习中有一个专有名词: <strong>最佳化(Optimization)</strong> .</p><p>由于生成式人工智能导论这门课只是人工智能的第一堂课, 因此在这里, 不会对最佳化进行详细的讲解.<br>我们可以简单将其理解为, 通过设定机器学习过程中的某些变量(这些变量也有专有名词: <strong>超参数, Hyperparameter</strong> &#x2F; <strong>初始参数, Initial Parameters</strong>), 从而确定不同的参数.</p><blockquote><p><strong>超参数</strong> : 训练开始前由人为设定的外部配置（例如学习率、神经网络的层数）。它们用来控制训练过程的运作方式，不会在训练过程中被算法自动更新。<br><strong>初始参数</strong> : 模型内部参数在训练开始前的起始数值。模型会从这些值开始，通过训练数据不断被修改和优化。</p></blockquote><h3 id=3-1-2-确定参数过程中的意外情况><a href=#3-1-2-确定参数过程中的意外情况 class=headerlink title="3.1.2 确定参数过程中的意外情况"></a>3.1.2 确定参数过程中的意外情况</h3><p>我们需要明确的几点是:</p><ul><li>训练是可能失败(模型输出的结果不符合训练资料)的</li><li>训练失败, 只能换一组超参数, 再试一次</li><li>但是在诸多研究中, 超参数的变更方式, 有迹可循</li></ul><hr><p>历经千辛万苦, 训练成功了, 恭喜你, 还有第二关要过, 也就是测试.<br>而关于测试, 我们也会碰到非常遗憾的事情:</p><ul><li>训练成功(模型针对训练资料的输出结果符合预期), 但测试失败(模型针对测试资料的输出结果不符合预期), 这种情况也有专有名词: <strong>Overfitting</strong></li></ul><h3 id=3-1-3-怎么让机器寻找到更加合适的参数><a href=#3-1-3-怎么让机器寻找到更加合适的参数 class=headerlink title="3.1.3 怎么让机器寻找到更加合适的参数"></a>3.1.3 怎么让机器寻找到更加合适的参数</h3><p>出现训练失败, 或者overfitting的情况时, 该怎么办?</p><ul><li>增加更多的训练限制, 换一种说法, 就是多样化我们的训练资料.</li><li>合理设定超参数与初始参数.</li></ul><p>这个初始参数该怎么找是个问题.<br>最常规的做法是随机选择, 也叫 <strong>Train from scratch</strong> .<br>但很明显, 随机的效率, 不够高, 远远不够高. 我们更希望能够找到某一个尽可能合理的值, 将其作为初始参数进行模型训练. 换句话说, 给模型训练一个比较正确的 <strong>先验知识</strong> .</p><h2 id=3-2-第一阶段-预训练-Pre-train><a href=#3-2-第一阶段-预训练-Pre-train class=headerlink title="3.2 第一阶段: 预训练(Pre-train)"></a>3.2 第一阶段: 预训练(Pre-train)</h2><h3 id=3-2-1-学会文字接龙的文本量><a href=#3-2-1-学会文字接龙的文本量 class=headerlink title="3.2.1 学会文字接龙的文本量"></a>3.2.1 学会文字接龙的文本量</h3><p>目前来说, 模型需要学的内容包含两个大方面:</p><ul><li>语言知识: 更类似于文法, 语法类的规则类内容</li><li>世界知识: 更类似于需要了解的知识性内容</li></ul><p>从文献来看, 语言知识真的比较好学:</p><p><img src=https://mug-chensblog-1310677143.cos.ap-beijing.myqcloud.com/Loading.svg data-original=https://major-course-1310677143.cos.ap-guangzhou.myqcloud.com/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/Chap.3/%E8%AF%AD%E8%A8%80%E7%9F%A5%E8%AF%86%E7%9A%84%E6%96%87%E6%9C%AC%E5%AD%A6%E4%B9%A0%E9%87%8F.png alt=学习语言知识所需的文本量></p><p>从典型值来看, 也许基于模型一亿个词汇, 就能够让它学会比较通用的语言知识. (深蓝色的线条)<br>与之相对的, 就算我们给予模型超越30亿的文本量, 也许我们也无法让模型学会足够的世界知识.(浅蓝色线条)</p><h3 id=3-2-2-自督导式学习><a href=#3-2-2-自督导式学习 class=headerlink title="3.2.2 自督导式学习"></a>3.2.2 自督导式学习</h3><p>尽管30亿的文本量看起来着实很多, 但好处在于, 这种需要作为学习资料的文本在当今的网络上简直是要多少有多少. 任何一段正常的文本, 都可以直接拿来当作训练资料.</p><p>这一过程中, 人工几乎并不介入训练本身, 而是让模型自行从大量的, 质量参差不齐的资料中自我学习. 这一阶段因此得到了一个专业名词: <strong>自督导式学习(Self-supervised Learning)</strong> .</p><p>当然, 在如今的互联网上, 资料太少往往不是个问题, 因此目前几乎全部模型的训练过程, 都会进行一定程度上的 <strong>资料清理</strong> , 这往往包括:</p><ul><li>去除有害内容(黄色内容 &#x2F; 暴力内容等等)</li><li>去除HTML Tag</li><li>去除”低品质”资料(通过预先训练好的资料分类器等等, 这往往也是一个模型)</li><li>去除重复资料</li></ul><p>通过如上的资料清理, 能够在模型训练的第一步就打下一个良好的基础.</p><h3 id=3-2-3-更大-更好-更强><a href=#3-2-3-更大-更好-更强 class=headerlink title="3.2.3 更大? 更好? 更强?"></a>3.2.3 更大? 更好? 更强?</h3><p>到此, 我们大概会进入一个常见的误区. 是不是模型参数越多, 训练资料数据量越大, 训练出的模型就越强?</p><p>前人与我们陷入了同样的误区, 并投入了实践.<br>OpenAI自2018年进行模型研发以来, 其实已经进行了相应的尝试, 它们的数据量如下:</p><ul><li>GPT-1: 117 Million Parameter, Read about 1GB Text</li><li>GPT-2: 1542 Million Parameter, Read about 50GB Text</li><li>GPT-3: 175 Billion Parameter, Read about 580GB Text</li></ul><p>但很遗憾, 直到GPT-3, 模型仍然表现的十分 “不受控” . 它往往不会老老实实的回答你的问题, 有时甚至会产生意想不到的输出格式.</p><p>如果读者还觉得不够, 同阶段, Google训练出了一个模型叫PaLM, 足足达到了 <strong>504 Billion Parameter</strong> 的参数大小, 但结果仍然如此.</p><p>因此, 事实证明, 只有这种简单的自督导式学习还不够, 语言模型的训练还需要更进一步的指导.</p><h2 id=3-3-第二阶段-指令微调-Instruction-Fine-tuning><a href=#3-3-第二阶段-指令微调-Instruction-Fine-tuning class=headerlink title="3.3 第二阶段: 指令微调(Instruction Fine-tuning)"></a>3.3 第二阶段: 指令微调(Instruction Fine-tuning)</h2><p>第一阶段完成了基础的资料累计, 但很显然, 这距离一个强大的, 能够正确回答问题的语言模型而言, 远远不够. 它接触到的语料不足以让它以正确的问答逻辑来回答问题.</p><p>这个阶段, 人工需要介入了.</p><h3 id=3-3-1-指令微调-Instruction-Fine-tuning><a href=#3-3-1-指令微调-Instruction-Fine-tuning class=headerlink title="3.3.1 指令微调 Instruction Fine-tuning"></a>3.3.1 指令微调 Instruction Fine-tuning</h3><p>所谓 <strong>指令微调</strong> , 指的是在这一阶段, 语言模型会再次接收到一系列新的信息, 但特殊的是, 这一系列新信息是以 <strong>指令-回复对(Instruction-Response pair)</strong> 来给出的.<br>这些指令回复对, 是人类自行产生的高质量资料, 需要耗费大量的人力物力来进行生产, 产生这一系列指令回复对的过程叫做 <strong>资料标注(Data Labeling)</strong> .</p><blockquote><p>事实上, 这一阶段的训练过程, 我们在Chap.1中也提到过它的另一个名字, 督导式学习(Supervised Learning &#x2F; Supervised Fine-tuning)</p></blockquote><hr><p>为什么不一开始就只用人类给出的资料?</p><p>这问题的答案比较现实. 太贵了.<br>要收集人类标注的, 高质量的对话, 需要的成本过高, 往往花费巨量成本搜集到的资料, 也不足以让语言模型成功对这个世界产生足够多的认知. 因此, 第一阶段预训练, 即便它的效果不佳, 资料质量不高, 但胜在能够以较低的成本来让模型满足大量基本认知.</p><hr><h3 id=3-3-2-Adapter><a href=#3-3-2-Adapter class=headerlink title="3.3.2 Adapter"></a>3.3.2 Adapter</h3><p>我们曾提到过, 要想提高模型的训练效果, 可以从两方面着手: 扩充资料以及变更初始参数.<br>显然, 对于这个指令微调阶段, 人工产生的资料实在是太贵了, 扩充资料显得不是很现实, 变更初始参数因而成为了比较常规的方式.<br>这个初始参数自然就是是从第一阶段的预训练拿来的.</p><p><img src=https://mug-chensblog-1310677143.cos.ap-beijing.myqcloud.com/Loading.svg data-original=https://major-course-1310677143.cos.ap-guangzhou.myqcloud.com/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/Chap.3/Fine-tuning%E5%88%9D%E5%A7%8B%E5%8F%82%E6%95%B0%E7%9A%84%E9%80%89%E6%8B%A9.png alt="Fine-tuning 初始参数的选择"></p><p>通过这种方式, 我们就能够让最终微调出的参数比较接近我们的初始参数(我们提到过的, 初始参数是最佳化寻找参数的起点). 当然, 如果我们还不放心, 那么我们完全可以借助另一种思路.</p><p><strong>Adapter</strong> 的思路是: 直接冻结模型原有的初始参数, 转而加上些额外的参数使得这个模型能够满足微调时提供资料的要求:</p><p><img src=https://mug-chensblog-1310677143.cos.ap-beijing.myqcloud.com/Loading.svg data-original=https://major-course-1310677143.cos.ap-guangzhou.myqcloud.com/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/Chap.3/Adapter.png alt=Adapter></p><p>当前最红火的Adapter示例即LoRA(Low-Rank Adaptation), 但课程原因, 这里不详述.</p><h3 id=3-3-3-Fine-tuning的方向><a href=#3-3-3-Fine-tuning的方向 class=headerlink title="3.3.3 Fine-tuning的方向?"></a>3.3.3 Fine-tuning的方向?</h3><p>显然, 这种指令微调的方式给予了我们第二次重塑模型表现的机会. 这同时也让微调这个行为, 有了不同的努力方向:</p><ul><li>通过不同风格的QA, 打造很多擅长不同领域的语言模型(专才)</li><li>收集一大堆的标注材料, 通通喂给模型, 打造一个各方面都很强大的语言模型(通才)</li></ul><p>我们已经理解了专才的培养方式, 那通才对我们而言就不会很难, 无非是看看量变能否引起质变的关系.<br>在2022年, 谷歌就曾做过相应的尝试, 谷歌对一个Pre-train的模型做微调时, 加入了 <strong>1.8k种任务</strong> , 得到的结果事实上还蛮喜人的.</p><p><img src=https://mug-chensblog-1310677143.cos.ap-beijing.myqcloud.com/Loading.svg data-original=https://major-course-1310677143.cos.ap-guangzhou.myqcloud.com/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/Chap.3/%E9%80%9A%E6%89%8DFine-tuning.png alt=通才Fine-tuning></p><p>当然, 从2026年初的视角来看, 通才模型是主流方向.</p><h3 id=3-3-4-画龙点睛与逆向工作><a href=#3-3-4-画龙点睛与逆向工作 class=headerlink title="3.3.4 画龙点睛与逆向工作"></a>3.3.4 画龙点睛与逆向工作</h3><p>我们上面讨论了这么多关于指令微调的事项, 尽管它们方向不同, 风格迥异, 但至今为止, 有一点是确定的:<br>指令微调是一个 <strong>画龙点睛</strong> 的工作, 资料在精不在多.</p><blockquote><p>在llama2等模型的论文中, 就已经给出了他们的结论, 他们仅用了上万规模的高质量资料集, 就能够让模型做到它应当做到的事情.</p></blockquote><p>那么, 既然我们不需要过多的资料, 这个指令微调的过程能不能让我们自己来做?<br><strong>不行</strong> , 因为从基本定义上来说, 我们就没有 <strong>高品质的资料</strong> .</p><p>好, 就是这里, 危险的想法开始出现了奥.<br>我们让一个现有的, 表现很好的语言模型, 自己产生出很多很多的QA对, 然后把这些它产生出来的QA对直接拿过来自己做Fine-tuning不就好了吗?</p><p>这个想法此前有人做过, 被称之为 <strong>逆向指令生成(Reverse Instruction Generation)</strong><br>不过显然, 这些大公司不希望这种事情的产生, 这不是给自己创造竞争对手嘛. 因此, 以OpenAI为例, 能够看到用户条款中类似这样的表述:</p><p><em>(c)Restrictions. … (iii)use output from the Services to develop models that compete with OpenAl;</em><br><del>不过这个条款真的没什么人在意就是了.</del></p><hr><p><strong>好!</strong><br>我们现在有了Fine-tuning的资料, 还缺什么? 还缺Pre-train的模型.<br>在2023年, 大家还拿不到非常优质的Pre-train模型, 这整个事情在这里就卡住了. 直到Meta将Llama的整个Pre-train模型开源, 这一切才迎刃而解.</p><p>至此, 人人都可以微调大语言模型的时代, 开始了.</p></div><hr><div class=reprint id=reprint-statement><div class=reprint__author><span class=reprint-meta style=font-weight:700><i class="fas fa-user">文章作者: </i></span><span class=reprint-info><a href=/about rel="external nofollow noreferrer">MUG-chen</a></span></div><div class=reprint__type><span class=reprint-meta style=font-weight:700><i class="fas fa-link">文章链接: </i></span><span class=reprint-info><a href=http://mug-chen.github.io/posts/61280.html>http://mug-chen.github.io/posts/61280.html</a></span></div><div class=reprint__notice><span class=reprint-meta style=font-weight:700><i class="fas fa-copyright">版权声明: </i></span><span class=reprint-info>本博客所有文章除特別声明外，均采用 <a href=https://creativecommons.org/licenses/by/4.0/deed.zh rel="external nofollow noreferrer" target=_blank>CC BY 4.0</a> 许可协议。转载请注明来源 <a href=/about target=_blank>MUG-chen</a> !</span></div></div><script async defer=defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class=tag_share style=display:block><div class=post-meta__tag-list style=display:inline-block><div class=article-tag><a href=/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/ ><span class="chip bg-color">人工智能</span> </a><a href=/tags/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/ ><span class="chip bg-color">生成式人工智能导论</span> </a><a href=/tags/Introduction-to-Generative-Artificial-Intelligence/ ><span class="chip bg-color">Introduction to Generative Artificial Intelligence</span></a></div></div><div class=post_share style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel=stylesheet type=text/css href=/libs/share/css/share.min.css><div id=article-share><div class=social-share data-sites=twitter,facebook,google,qq,qzone,wechat data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src=/libs/share/js/social-share.min.js></script></div></div></div></div></div><article id=prenext-posts class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos=fade-up data-aos=fade-up><div class="article-badge left-badge text-color"><i class="far fa-dot-circle"></i>&nbsp;本篇</div><div class=card><a href=/posts/61280.html><div class=card-image><img src=/medias/featureimages/12.jpg class=responsive-img alt=生成式人工智能导论-Chap.3> <span class=card-title>生成式人工智能导论-Chap.3</span></div></a><div class="card-content article-content"><div class="summary block-with-text">生成式人工智能导论第三部分</div><div class=publish-info><span class=publish-date><i class="far fa-clock fa-fw icon-date"></i>2025-12-09 </span><span class=publish-author><i class="fas fa-bookmark fa-fw icon-category"></i> <a href=/categories/Study-Notes/ class=post-category>Study Notes </a><a href=/categories/Study-Notes/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/ class=post-category>人工智能</a></span></div></div><div class="card-action article-tags"><a href=/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/ ><span class="chip bg-color">人工智能</span> </a><a href=/tags/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/ ><span class="chip bg-color">生成式人工智能导论</span> </a><a href=/tags/Introduction-to-Generative-Artificial-Intelligence/ ><span class="chip bg-color">Introduction to Generative Artificial Intelligence</span></a></div></div></div><div class="article col s12 m6" data-aos=fade-up><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class=card><a href=/posts/12193.html><div class=card-image><img src=/medias/featureimages/13.jpg class=responsive-img alt=生成式人工智能导论-Chap.2> <span class=card-title>生成式人工智能导论-Chap.2</span></div></a><div class="card-content article-content"><div class="summary block-with-text">生成式人工智能导论第二部分</div><div class=publish-info><span class=publish-date><i class="far fa-clock fa-fw icon-date"></i>2025-10-20 </span><span class=publish-author><i class="fas fa-bookmark fa-fw icon-category"></i> <a href=/categories/Study-Notes/ class=post-category>Study Notes </a><a href=/categories/Study-Notes/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/ class=post-category>人工智能</a></span></div></div><div class="card-action article-tags"><a href=/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/ ><span class="chip bg-color">人工智能</span> </a><a href=/tags/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%BC%E8%AE%BA/ ><span class="chip bg-color">生成式人工智能导论</span> </a><a href=/tags/Introduction-to-Generative-Artificial-Intelligence/ ><span class="chip bg-color">Introduction to Generative Artificial Intelligence</span></a></div></div></div></div></article></div><script type=text/javascript src=/libs/codeBlock/codeBlockFuction.js></script><script type=text/javascript src=/libs/prism/prism.min.js></script><script type=text/javascript src=/libs/codeBlock/codeLang.js></script><script type=text/javascript src=/libs/codeBlock/codeCopy.js></script><script type=text/javascript src=/libs/codeBlock/codeShrink.js></script></div><div id=toc-aside class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style=background-color:#fff><div class=toc-title><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id=toc-content></div></div></div></div><div id=floating-toc-btn class=hide-on-med-and-down><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src=/libs/tocbot/tocbot.min.js></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=parseInt(.4*$(window).height()-64),e=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>t?e.addClass("toc-fixed"):e.removeClass("toc-fixed")});const n="expanded";let i=$("#toc-aside"),l=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){i.hasClass(n)?(i.removeClass(n).hide(),l.removeClass("l9")):(i.addClass(n).show(),l.addClass("l9"));var e="artDetail",o="prenext-posts";if(0!==(e=$("#"+e)).length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#"+o).width(t)}})})</script></main><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style=margin-bottom:15px!important><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id=year>2022-2026</span> <a href=/about target=_blank>MUG-chen</a> |&nbsp;Powered by&nbsp;<a href=https://hexo.io/ target=_blank>Hexo</a> |&nbsp;Theme&nbsp;<a href=https://github.com/blinkfox/hexo-theme-matery target=_blank>Matery</a><br><span id=busuanzi_container_site_pv>&nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp; <span id=busuanzi_value_site_pv class=white-color></span> </span><span id=busuanzi_container_site_uv>&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp; <span id=busuanzi_value_site_uv class=white-color></span></span><br><span id=sitetime>Loading ...</span><script>var calcSiteTime=function(){var e=new Date,t="2022",n=e.getFullYear(),i=e.getMonth()+1,a=e.getDate(),r=e.getHours(),o=e.getMinutes(),e=e.getSeconds(),s=Date.UTC(t,"12","25","22","45","0"),i=Date.UTC(n,i,a,r,o,e)-s,a=Math.floor(i/31536e6),r=Math.floor(i/864e5-365*a);t===String(n)?(document.getElementById("year").innerHTML=n,o="This site has been running for "+r+" days",o="本站已运行 "+r+" 天",document.getElementById("sitetime").innerHTML=o):(document.getElementById("year").innerHTML=t+" - "+n,e="This site has been running for "+a+" years and "+r+" days",e="本站已运行 "+a+" 年 "+r+" 天",document.getElementById("sitetime").innerHTML=e)};calcSiteTime()</script><br></div><div class="col s12 m4 l4 social-link social-statis"><a href=https://github.com/MUG-chen class=tooltipped target=_blank data-tooltip=访问我的GitHub data-position=top data-delay=50><i class="fab fa-github"></i></a></div></div></footer><div class=progress-bar></div><div id=searchModal class=modal><div class=modal-content><div class=search-header><span class=title><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type=search id=searchInput name=s placeholder=请输入搜索的关键字 class=search-input></div><div id=searchResult></div></div></div><script type=text/javascript>$(function(){!function(t,r,s){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var e=$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),t=document.getElementById(r),n=document.getElementById(s);t.addEventListener("input",function(){var o='<ul class="search-result-list">',h=this.value.trim().toLowerCase().split(/[\s\-]+/);n.innerHTML="",this.value.trim().length<=0||(e.forEach(function(t){var n,e,r,s=!0,i=t.title.trim().toLowerCase(),l=t.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),a=0===(a=t.url).indexOf("/")?t.url:"/"+a,c=-1,u=-1;""!==i&&""!==l&&h.forEach(function(t,e){n=i.indexOf(t),c=l.indexOf(t),n<0&&c<0?s=!1:(c<0&&(c=0),0===e&&(u=c))}),s&&(o+="<li><a href='"+a+"' class='search-result-title'>"+i+"</a>",a=t.content.trim().replace(/<[^>]+>/g,""),0<=u&&(t=u+80,(t=0===(e=(e=u-20)<0?0:e)?100:t)>a.length&&(t=a.length),r=a.substr(e,t),h.forEach(function(t){var e=new RegExp(t,"gi");r=r.replace(e,'<em class="search-keyword">'+t+"</em>")}),o+='<p class="search-result">'+r+"...</p>"),o+="</li>")}),o+="</ul>",n.innerHTML=o)})}})}("/search.xml","searchInput","searchResult")})</script><div class=stars-con><div id=stars></div><div id=stars2></div><div id=stars3></div></div><script>function switchNightMode(){$('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($("body")),setTimeout(function(){$("body").hasClass("DarkMode")?($("body").removeClass("DarkMode"),localStorage.setItem("isDark","0"),$("#sum-moon-icon").removeClass("fa-sun").addClass("fa-moon")):($("body").addClass("DarkMode"),localStorage.setItem("isDark","1"),$("#sum-moon-icon").addClass("fa-sun").removeClass("fa-moon")),setTimeout(function(){$(".Cuteen_DarkSky").fadeOut(1e3,function(){$(this).remove()})},2e3)})}</script><div id=backTop class=top-scroll><a class="btn-floating btn-large waves-effect waves-light" href=#!><i class="fas fa-arrow-up"></i></a></div><script src=/libs/materialize/materialize.min.js></script><script src=/libs/masonry/masonry.pkgd.min.js></script><script src=/libs/aos/aos.js></script><script src=/libs/scrollprogress/scrollProgress.min.js></script><script src=/libs/lightGallery/js/lightgallery-all.min.js></script><script src=/js/matery.js></script><script type=text/javascript>var windowWidth=$(window).width();768<windowWidth&&document.write('<script type="text/javascript" src="/libs/others/snow.js"><\/script>')</script><script src=https://ssl.captcha.qq.com/TCaptcha.js></script><script src=/libs/others/TencentCaptcha.js></script><button id=TencentCaptcha data-appid=xxxxxxxxxx data-cbfn=callback type=button hidden></button><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0],e=(t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",document.getElementsByTagName("script")[0]);e.parentNode.insertBefore(t,e)}()</script><script async src=/libs/others/busuanzi.pure.mini.js></script><script src=/libs/instantpage/instantpage.js type=module></script><div id=loading-box><div class=loading-left-bg></div><div class=loading-right-bg></div><div class=spinner-box><div class=configure-border-1><div class=configure-core></div></div><div class=configure-border-2><div class=configure-core></div></div><div class=loading-word>加载中...</div></div></div><script>window.addEventListener("load",function(){document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")},!1)</script><style>[bg-lazy]{background-image:none!important;background-color:#eee!important}</style><script>window.imageLazyLoadSetting={isSPA:!0,preloadRatio:3,processImages:null}</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})})</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a=c[o],i=function(){c=c.filter(function(t){return a!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(a)};(t=a).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),i()):(e=new Image,n=t.getAttribute("data-original"),e.onload=function(){t.src=n,t.removeAttribute("data-original"),i()},t.src!==n&&(e.src=n))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this)</script></body></html>